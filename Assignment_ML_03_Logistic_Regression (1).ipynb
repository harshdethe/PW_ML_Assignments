{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "   - Logistic Regression is a statistical method used for binary classification tasks, where the goal is to predict the probability of an outcome belonging to one of two categories (e.g., yes/no, spam/not spam). It models the relationship between a dependent variable and one or more independent variables using a logistic function, which transforms the linear combination of inputs into a value between 0 and 1, representing the probability of the positive class and the difference is Linear Regression predicts continuous numerical values by fitting a straight line to the data (minimizing the sum of squared errors), Logistic Regression is designed for categorical outcomes and uses a sigmoid curve to output probabilities, optimizing maximum likelihood estimation.\n",
        "\n",
        "2. Explain the role of the Sigmoid function in Logistic Regression.\n",
        "   - The Sigmoid function in Logistic Regression helps turn the model’s output into a probability. When a Logistic Regression model makes a prediction, it first calculates a value by adding up the input features multiplied by their weights. This value can be any number, positive or negative. The Sigmoid function then takes this number and converts it into a value between 0 and 1, which represents the probability that something belongs to a certain class. For example, if the result is close to 1, it means the model is confident the input belongs to the “yes” or “positive” class, if it’s close to 0, it means “no” or “negative.” The Sigmoid function also helps the model learn during training because it is smooth and easy to work with mathematically.\n",
        "3. What is Regularization in Logistic Regression and why is it needed?\n",
        "   - Regularization in Logistic Regression is a technique used to prevent the model from overfitting the training data. Overfitting happens when the model learns not only the main patterns in the data but also the noise or random fluctuations, which makes it perform poorly on new, unseen data. Regularization helps control this by adding a penalty term to the model’s cost function, which discourages the model from assigning very large weights to any particular feature. Basically it keeps the model simpler and more general.There are two common types of regularization: L1 (Lasso) and L2 (Ridge). L1 regularization can make some feature weights exactly zero, which helps in feature selection, while L2 regularization spreads the penalty across all weights, keeping them small but nonzero. Regularization is important because it improves the model’s ability to generalize to new data, reduces overfitting, and leads to more stable and reliable predictions.\n",
        "\n",
        "4. What are some common evaluation metrics for classification models, and\n",
        "why are they important?\n",
        "   - Common evaluation metrics for classification models include accuracy, precision, recall, F1-score, and the ROC-AUC score. These metrics are important because they help measure how well a model performs, especially when dealing with different types of data or imbalanced classes.Accuracy measures the overall percentage of correct predictions made by the model, but it can be misleading when one class is much larger than the other. Precision shows how many of the predicted positive cases are actually positive, which is useful when the cost of false positives is high. Recall measures how many of the actual positive cases the model correctly identified, which is important when missing positive cases is costly, such as in medical diagnoses. The F1-score combines precision and recall into a single number, providing a balance between the two when both are important. Lastly, the ROC-AUC score measures how well the model can distinguish between classes across all threshold levels, showing its overall ability to separate positive and negative examples.These metrics are essential because they give a more complete picture of a model’s strengths and weaknesses, helping data scientists choose the best model for a specific problem.\n"
      ],
      "metadata": {
        "id": "kMxFEHdkJtwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "# splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "# (Use Dataset from sklearn package)\n",
        "# (Include your Python code and output in the code box below.)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load a sample dataset from sklearn\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# Convert  into a  DataFrame\n",
        "df = pd.DataFrame(data=cancer.data, columns=cancer.feature_names)\n",
        "df['target'] = cancer.target\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train a model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nLogistic Regression Model Accuracy: {}%\".format(round(accuracy * 100),2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmZPWwrvNffD",
        "outputId": "ce906856-2222-4842-ad87-3b70bd44f926"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Model Accuracy: 96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Write a Python program to train a Logistic Regression model using L2\n",
        "# regularization (Ridge) and print the model coefficients and accuracy.\n",
        "# (Use Dataset from sklearn package)\n",
        "# (Include your Python code and output in the code box below.)\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load a sample dataset from sklearn\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# Convert  into a  DataFrame\n",
        "df = pd.DataFrame(data=cancer.data, columns=cancer.feature_names)\n",
        "df['target'] = cancer.target\n",
        "\n",
        "# Split dataset into features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train Logistic Regression model with L2 regularization\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print model coefficients and accuracy\n",
        "print(\"\\nModel Coefficients:\")\n",
        "print(model.coef_)\n",
        "\n",
        "print(\"\\nModel Intercept:\")\n",
        "print(model.intercept_)\n",
        "\n",
        "print(\"\\nLogistic Regression Model Accuracy with L2 Regularization (Ridge): {:.2f}%\".format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbsLFoPUPgTl",
        "outputId": "a96c8cf7-b0f6-405c-b88d-c234d56d5b0d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Coefficients:\n",
            "[[ 2.09981182  0.13248576 -0.10346836 -0.00255646 -0.17024348 -0.37984365\n",
            "  -0.69120719 -0.4081069  -0.23506963 -0.02356426 -0.0854046   1.12246945\n",
            "  -0.32575716 -0.06519356 -0.02371113  0.05960156  0.00452206 -0.04277587\n",
            "  -0.04148042  0.01425051  0.96630267 -0.37712622 -0.05858253 -0.02395975\n",
            "  -0.31765956 -1.00443507 -1.57134711 -0.69351401 -0.84095566 -0.09308282]]\n",
            "\n",
            "Model Intercept:\n",
            "[2.13128402]\n",
            "\n",
            "Logistic Regression Model Accuracy with L2 Regularization (Ridge): 95.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Write a Python program to train a Logistic Regression model for multiclass\n",
        "# classification using multi_class='ovr' and print the classification report.\n",
        "# (Use Dataset from sklearn package)\n",
        "# (Include your Python code and output in the code box below.)\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load a sample dataset from sklearn\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# Convert  into a  DataFrame\n",
        "df = pd.DataFrame(data=cancer.data, columns=cancer.feature_names)\n",
        "df['target'] = cancer.target\n",
        "\n",
        "# Split the dataset into features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train Logistic Regression model with multi_class='ovr'\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report for Logistic Regression:\\n\",report)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjkEq7MLRB6V",
        "outputId": "06014d31-8003-41e3-fc9f-ed6530036e53"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94        43\n",
            "           1       0.95      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "# hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "# accuracy.\n",
        "# (Use Dataset from sklearn package)\n",
        "# (Include your Python code and output in the code box below.)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Load a sample dataset from sklearn\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# Convert  into a  DataFrame\n",
        "df = pd.DataFrame(data=cancer.data, columns=cancer.feature_names)\n",
        "df['target'] = cancer.target\n",
        "\n",
        "# Split the dataset into features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "\n",
        "\n",
        "# Define the hyperparameter grid to search\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "#  Apply GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "#  Get the best parameters and validation accuracy\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_params)\n",
        "print(\"\\nBest Cross-Validation Accuracy: {:.2f}%\".format(best_score * 100))\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nTest Set Accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TreoXPKoTBBV",
        "outputId": "8b86cbe6-3dae-422c-9cd5-df2351058d2f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters:\n",
            "{'C': 100, 'penalty': 'l1'}\n",
            "\n",
            "Best Cross-Validation Accuracy: 96.70%\n",
            "\n",
            "Test Set Accuracy: 98.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Write a Python program to standardize the features before training Logistic\n",
        "# Regression and compare the model's accuracy with and without scaling.\n",
        "# (Use Dataset from sklearn package)\n",
        "# (Include your Python code and output in the code box below.)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the  dataset\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# Convert  into a  DataFrame\n",
        "df = pd.DataFrame(data=cancer.data, columns=cancer.feature_names)\n",
        "df['target'] = cancer.target\n",
        "\n",
        "# Split dataset into features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression without feature scaling\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Standardize features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression with scaled features\n",
        "model_scaled = LogisticRegression(max_iter=200)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Print and compare accuracies\n",
        "print(\"Accuracy without scaling: {:.2f}%\".format(accuracy_no_scaling * 100))\n",
        "print(\"Accuracy with scaling: {:.2f}%\".format(accuracy_with_scaling * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3xvY6MvUQAk",
        "outputId": "0cf09aee-2c1f-43d7-a8fd-baedb99e21b1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 95.61%\n",
            "Accuracy with scaling: 97.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Imagine you are working at an e-commerce company that wants to\n",
        "predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.\n",
        "    - To build a Logistic Regression model for predicting customer responses in an imbalanced dataset where only 5% of customers respond, I would follow a structured approach. First, I would begin with data preprocessing, handling missing values, encoding categorical variables, and analyzing feature distributions. Since Logistic Regression is sensitive to feature scales, I would apply feature scaling, such as standardization, to ensure numerical features are on comparable scales. Given the extreme class imbalance, I would implement techniques to address this, such as using class weighting in Logistic Regression or resampling methods like SMOTE (Synthetic Minority Over-sampling Technique) to create a more balanced training set. Next, I would perform hyperparameter tuning using tools like GridSearchCV or RandomizedSearchCV to optimize parameters such as the regularization strength C and the type of regularization (l1 or l2) while considering cross-validation strategies to prevent overfitting. For model evaluation, accuracy alone would be misleading due to class imbalance, so I would rely on metrics like precision, recall, F1-score, and AUC-ROC, focusing particularly on recall or F1 for the minority class to capture as many responders as possible. Finally, I would validate the model using a hold-out test set or cross validation and monitor business relevant KPIs, such as the predicted response rate, to ensure the model’s predictions are actionable and aligned with marketing objectives.\n"
      ],
      "metadata": {
        "id": "yzGzB0R0VHEc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gsfltRuWVWMD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}